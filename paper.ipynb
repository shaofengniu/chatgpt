{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyMuPDFLoader\n",
    "loader = PyMuPDFLoader(\"1706.03762.pdf\")\n",
    "data = loader.load()\n",
    "file_content = '\\n'.join([d.page_content for d in data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import TokenTextSplitter\n",
    "text_splitter = TokenTextSplitter(chunk_size=3000, chunk_overlap=2)\n",
    "texts = text_splitter.create_documents([file_content])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, t in enumerate(texts):\n",
    "    t.page_content = 'PAGE %d\\n\\n%s' % (i+1, t.page_content) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "chat = ChatOpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "REFINE_PROMPT_TMPL = '''\n",
    "As a knowledgeable AI, your task is to list all the sections of a scientific paper up to the provided point, excluding tables, figures, and references.\n",
    "The paper's content will be presented sequentially, and you must accurately represent the relationships between sections and their respective subsections in your list.\n",
    "You will be given an existing answer that has been generated so far.\n",
    "\n",
    "EXISTING ANSWER:\n",
    "{existing_answer}\n",
    "\n",
    "Adhere to the given format and only refine the answer if necessary, using the additional context provided below.\n",
    "Focus on identifying the section titles and their corresponding subsections that are explicitly mentioned in the text. Do not add extra details or overinterpret the content.\n",
    "If the additional context is not helpful or no changes are required, you may return the original answer without any changes.\n",
    "\n",
    "{text}\n",
    "\n",
    "ANSWER:\n",
    "'''\n",
    "REFINE_PROMPT = PromptTemplate(\n",
    "    input_variables=[\"existing_answer\", \"text\"],\n",
    "    template=REFINE_PROMPT_TMPL,\n",
    ")\n",
    "\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "As a knowledgeable AI, your task is to list all the sections of a scientific paper up to the provided point, excluding tables, figures, and references.\n",
    "The paper's content will be presented sequentially, and you must accurately represent the relationships between sections and their respective subsections in your list.\n",
    "Focus on identifying the section titles and their corresponding subsections that are explicitly mentioned in the text. Do not add extra details or overinterpret the content.\n",
    "-------------------\n",
    "{text}\n",
    "-------------------\n",
    "ANSWER:\n",
    "\"\"\"\n",
    "PROMPT = PromptTemplate(template=prompt_template, input_variables=[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "refine_chain = load_summarize_chain(chat, chain_type=\"refine\", verbose=True, \n",
    "                                    refine_prompt=REFINE_PROMPT, \n",
    "                                    question_prompt=PROMPT,\n",
    "                                    return_intermediate_steps=True,\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = refine_chain({\"input_documents\": texts}, return_only_outputs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Abstract\n",
      "2. Introduction\n",
      "3. Background\n",
      "   - Recurrent neural networks\n",
      "   - Attention mechanisms\n",
      "   - Self-attention\n",
      "   - End-to-end memory networks\n",
      "4. Model Architecture\n",
      "   - Encoder and Decoder Stacks\n",
      "   - Attention\n",
      "      - Scaled Dot-Product Attention\n",
      "      - Multi-Head Attention\n",
      "      - Applications of Attention in our Model\n",
      "\n",
      "\n",
      "1. Abstract\n",
      "2. Introduction\n",
      "3. Background\n",
      "   - Recurrent neural networks\n",
      "   - Attention mechanisms\n",
      "   - Self-attention\n",
      "   - End-to-end memory networks\n",
      "4. Model Architecture\n",
      "   - Encoder and Decoder Stacks\n",
      "   - Attention\n",
      "      - Scaled Dot-Product Attention\n",
      "      - Multi-Head Attention\n",
      "      - Applications of Attention in our Model\n",
      "   - Position-wise Feed-Forward Networks\n",
      "   - Embeddings and Softmax\n",
      "   - Positional Encoding\n",
      "5. Why Self-Attention\n",
      "6. Training\n",
      "   - Training Data and Batching\n",
      "   - Hardware and Schedule\n",
      "   - Optimizer\n",
      "   - Regularization\n",
      "7. Results\n",
      "   - Machine Translation\n",
      "\n",
      "\n",
      "1. Abstract\n",
      "2. Introduction\n",
      "3. Background\n",
      "   - Recurrent neural networks\n",
      "   - Attention mechanisms\n",
      "   - Self-attention\n",
      "   - End-to-end memory networks\n",
      "4. Model Architecture\n",
      "   - Encoder and Decoder Stacks\n",
      "   - Attention\n",
      "      - Scaled Dot-Product Attention\n",
      "      - Multi-Head Attention\n",
      "      - Applications of Attention in our Model\n",
      "   - Position-wise Feed-Forward Networks\n",
      "   - Embeddings and Softmax\n",
      "   - Positional Encoding\n",
      "5. Why Self-Attention\n",
      "6. Training\n",
      "   - Training Data and Batching\n",
      "   - Hardware and Schedule\n",
      "   - Optimizer\n",
      "   - Regularization\n",
      "   - Model Variations\n",
      "      - Varying number of attention heads and dimensions\n",
      "      - Importance of attention key size\n",
      "      - Effect of model size and dropout\n",
      "      - Replacing sinusoidal positional encoding with learned embeddings\n",
      "   - English Constituency Parsing\n",
      "7. Results\n",
      "   - Machine Translation\n",
      "   - English Constituency Parsing\n",
      "8. Conclusion\n",
      "9. Acknowledgements\n",
      "10. References\n",
      "\n",
      "\n",
      "1. Abstract\n",
      "2. Introduction\n",
      "3. Background\n",
      "   - Recurrent neural networks\n",
      "   - Attention mechanisms\n",
      "   - Self-attention\n",
      "   - End-to-end memory networks\n",
      "4. Model Architecture\n",
      "   - Encoder and Decoder Stacks\n",
      "   - Attention\n",
      "      - Scaled Dot-Product Attention\n",
      "      - Multi-Head Attention\n",
      "      - Applications of Attention in our Model\n",
      "   - Position-wise Feed-Forward Networks\n",
      "   - Embeddings and Softmax\n",
      "   - Positional Encoding\n",
      "5. Why Self-Attention\n",
      "6. Training\n",
      "   - Training Data and Batching\n",
      "   - Hardware and Schedule\n",
      "   - Optimizer\n",
      "   - Regularization\n",
      "   - Model Variations\n",
      "      - Varying number of attention heads and dimensions\n",
      "      - Importance of attention key size\n",
      "      - Effect of model size and dropout\n",
      "      - Replacing sinusoidal positional encoding with learned embeddings\n",
      "   - English Constituency Parsing\n",
      "7. Results\n",
      "   - Machine Translation\n",
      "   - English Constituency Parsing\n",
      "   - Attention Visualizations\n",
      "8. Conclusion\n",
      "9. Acknowledgements\n",
      "10. References\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for s in resp['intermediate_steps']:\n",
    "    print(s+'\\n\\n')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatgpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
